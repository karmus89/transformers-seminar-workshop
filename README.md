# transformers-seminar-workshop

## Resources

Attention is all you need (2017)
 - [arXiv](https://arxiv.org/pdf/1706.03762.pdf)
 - [The Annotated Transformer: notebook of paper with code](http://nlp.seas.harvard.edu/annotated-transformer/)
 - [Stanford CS224N: NLP with Deep Learning | Winter 2019 | Lecture 14 â€“ Transformers and Self-Attention](https://youtu.be/5vcj8kSwBCY)

HuggingFace Course
 - [YouTube playlist](https://www.youtube.com/playlist?list=PLo2EIpI_JMQvWfQndUesu0nPBAtZ9gP1o)

Jay Alammar's blog posts about core concepts
 - [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
 - [The Illustrated GPT-2 (Visualizing Transformer Language Models)](https://jalammar.github.io/illustrated-gpt2/)
 - [Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)

Udemy course "Natural Language Processing: NLP With Transformers in Python"
 - [Github repo](https://github.com/jamescalam/transformers)

Peter Bloems blog "Transformers from scratch"
 - [Link](https://peterbloem.nl/blog/transformers)